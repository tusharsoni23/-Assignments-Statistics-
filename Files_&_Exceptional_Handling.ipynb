{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "#1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where multiprocessing is a better choice.\n#ans.\nMultithreading\n\n.Preferable Scenarios:**\n\n1. I/O-Bound Tasks:**\n   - When tasks involve a lot of waiting (like network calls, file I/O, or database queries), multithreading can be more efficient. Threads can switch context when one is waiting for I/O, allowing others to run in the meantime.\n\n2.Shared Memory Needs:**\n   - If tasks need to share data frequently or maintain shared state, multithreading allows easy access to shared memory without the overhead of inter-process communication (IPC).\n\n3.Lightweight Context Switching:**\n   - Threads are generally lighter than processes in terms of memory and context-switching overhead, making them suitable for tasks that require many concurrent operations without high resource usage.\n\n4. Low Latency Requirements:**\n   - Applications requiring low latency, such as real-time data processing, can benefit from the quick context switching that threads provide.\n\n5.Simpler Model for Shared Resources:**\n   - In applications where synchronization is manageable, threads can simplify access to shared resources, avoiding the complexities of inter-process communication.\n\n Multiprocessing\n\nPreferable Scenarios:**\n\n1. CPU-Bound Tasks:**\n   - When tasks are compute-intensive and require significant CPU resources, multiprocessing is  \npreferable. It allows tasks to run in parallel across multiple CPU cores, fully utilizing available hardware.\n\n2. Isolation Needs:**\n   - Processes have their own memory space, making them safer against crashes or data corruption caused by other processes. This is useful in applications where stability is critical.\n\n3. Global Interpreter Lock (GIL) Limitation:**\n   - In Python, for example, the GIL prevents multiple native threads from executing Python bytecodes simultaneously. Multiprocessing can bypass this limitation by using separate memory spaces.\n\n4. Heavy Memory Usage:**\n   - Applications that require large amounts of memory may benefit from multiprocessing, as each process has its own memory allocation, reducing contention for shared memory.\n\n5. Fault Tolerance:**\n   - If one process crashes, it doesn't affect others. This isolation is beneficial for applications requiring higher fault tolerance.\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#2. Describe what a process pool is and how it helps in managing multiple processes efficiently\n#Ans.\nA **process pool** is a collection of pre-instantiated processes that can be used to execute tasks concurrently. Instead of creating and destroying processes on the fly, which can be resource-intensive and slow, a process pool allows for efficient reuse of existing processes. Here’s how it works and how it helps in managing multiple processes:\n\n### Key Features of a Process Pool\n\n1. **Reusability:**\n   - Once a process in the pool is created, it remains available for executing multiple tasks. This reduces the overhead associated with process creation and destruction.\n\n2. **Task Queuing:**\n   - When a task is submitted to the process pool, it is placed in a queue. Available processes from the pool take tasks from the queue, ensuring efficient workload distribution.\n\n3. **Resource Management:**\n   - A process pool can limit the number of concurrent processes, preventing system overload. This helps manage system resources effectively, avoiding scenarios where too many processes compete for CPU and memory.\n\n4. **Load Balancing:**\n   - The process pool can balance the load among its processes, helping to ensure that all processes are utilized evenly and efficiently.\n\n### Benefits of Using a Process Pool\n\n1. **Improved Performance:**\n   - By reusing processes, a process pool can significantly reduce the latency associated with starting new processes, leading to faster execution times for batch jobs or concurrent tasks.\n\n2. **Reduced Overhead:**\n   - The costs of context switching and memory allocation are minimized, as the pool maintains a stable number of processes.\n\n3. **Simplified Programming Model:**\n   - Developers can submit tasks to the pool without worrying about the details of process management, such as creation and termination.\n\n4. Error Handling:**\n   - Many process pool implementations include built-in mechanisms for handling errors in worker processes, which can improve the robustness of applications.\n\n5. Scalability:**\n   - A process pool can easily be scaled up or down based on system resources and application needs, allowing for flexible resource allocation.\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#3. Explain what multiprocessing is and why it is used in Python program\n#ans\nMultiprocessing is a programming paradigm that allows multiple processes to run concurrently, enabling parallel execution of tasks. In Python, the `multiprocessing` module provides a straightforward way to create and manage separate processes, leveraging multiple CPU cores to improve performance, especially for CPU-bound tasks.\n\n# Key Concepts of Multiprocessing\n\n1. Processes vs. Threads:**\n   - Unlike threads, which share the same memory space, processes have their own memory allocation. This isolation provides better stability and security, as one process crashing doesn’t directly affect others.\n\n2. Parallelism:**\n   - Multiprocessing enables true parallelism by allowing multiple processes to run on different CPU cores. This is particularly beneficial for CPU-bound tasks that require significant computation.\n\n3. Inter-Process Communication (IPC):**\n   - The `multiprocessing` module provides mechanisms like pipes and queues for processes to communicate and share data safely, despite their memory isolation.\n\n### Why Use Multiprocessing in Python?\n\n1. Bypassing the Global Interpreter Lock (GIL):**\n   - Python's GIL allows only one thread to execute Python bytecode at a time. This can be a bottleneck for CPU-bound tasks. Multiprocessing circumvents the GIL, allowing multiple processes to run concurrently, fully utilizing available CPU resources.\n\n2. Improved Performance:**\n   - For CPU-intensive applications, using multiple processes can significantly reduce execution time by distributing the workload across multiple cores.\n\n3. Better Resource Utilization:**\n   - Multiprocessing enables more efficient use of multi-core systems, improving overall application performance and responsiveness.\n\n4. Fault Isolation:**\n   - Processes are isolated; if one fails, it doesn't crash the entire application. This makes multiprocessing suitable for tasks where reliability is critical.\n\n5. Scalability:**\n   - Multiprocessing can easily scale to use more processes as needed, adapting to varying workloads or hardware capabilities.\n\n6. Ask Parallelism:**\n   - It is suitable for tasks that can be divided into independent units of work, such as data processing, simulations, or web scraping.\n\n### Example Use Cases\n\n- Data Analysis:** Processing large datasets in parallel to speed up computations.\n- Web Servers:** Handling multiple requests simultaneously.\n- Machine Learning:** Training models using parallel data processing.\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#4. Write a Python program using multithreading where one thread adds numbers to a list, and another  thread removes numbers from the list. Implement a mechanism to avoid race conditions using  threading.Lock\nimport threading\nimport time\nimport random\n\n# Shared list\nshared_list = []\n# Lock to manage access to the shared list\nlock = threading.Lock()\n\ndef add_numbers():\n    \"\"\"Thread function to add numbers to the shared list.\"\"\"\n    for i in range(10):\n        time.sleep(random.uniform(0.1, 0.5))  # Simulate some work\n        with lock:  # Acquire the lock before modifying the list\n            shared_list.append(i)\n            print(f\"Added: {i}. Current list: {shared_list}\")\n\ndef remove_numbers():\n    \"\"\"Thread function to remove numbers from the shared list.\"\"\"\n    for i in range(10):\n        time.sleep(random.uniform(0.1, 0.5))  # Simulate some work\n        with lock:  # Acquire the lock before modifying the list\n            if shared_list:\n                removed_value = shared_list.pop(0)\n                print(f\"Removed: {removed_value}. Current list: {shared_list}\")\n            else:\n                print(\"Tried to remove from an empty list.\")\n\n# Creating threads\nadder_thread = threading.Thread(target=add_numbers)\nremover_thread = threading.Thread(target=remove_numbers)\n\n# Starting threads\nadder_thread.start()\nremover_thread.start()\n\n# Wait for both threads to complete\nadder_thread.join()\nremover_thread.join()\n\nprint(\"Final list:\", shared_list)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#5. Describe the methods and tools available in Python for safely sharing data between threads and  processes\n#ans.\nIn Python, safely sharing data between threads and processes involves using specific tools and methods designed to manage concurrency and prevent issues like race conditions. Here’s an overview of the main tools available for both threads and processes:\n\n### For Threading\n\n1. **`threading.Lock`:**\n   - A simple lock that allows only one thread to access a resource at a time. When one thread acquires the lock, others must wait until it is released.\n   ```python\n   lock = threading.Lock()\n   with lock:\n       # Critical section\n   ```\n\n2. **`threading.RLock`:**\n   - A reentrant lock that can be acquired multiple times by the same thread. It’s useful when a thread needs to enter the same critical section multiple times.\n   ```python\n   rlock = threading.RLock()\n   with rlock:\n       # Critical section\n   ```\n\n3. **`threading.Semaphore`:**\n   - A semaphore allows a specified number of threads to access a resource concurrently. This can be useful for controlling access to a limited number of resources.\n   ```python\n   semaphore = threading.Semaphore(value=2)\n   with semaphore:\n       # Access resource\n   ```\n\n4. **`threading.Condition`:**\n   - A condition variable allows threads to wait for certain conditions to be met. It can be used to signal one or more threads that a condition has changed.\n   ```python\n   condition = threading.Condition()\n   with condition:\n       condition.wait()  # Wait until notified\n       # Proceed after being notified\n   ```\n\n5. **`threading.Event`:**\n   - An event is a simple flag that can be set or cleared. It is useful for signaling between threads.\n   ```python\n   event = threading.Event()\n   event.set()  # Set the event\n   event.clear()  # Clear the event\n   ```\n\n### For Multiprocessing\n\n1. **`multiprocessing.Queue`:**\n   - A thread- and process-safe FIFO queue for sharing data between processes. It allows you to add and retrieve items safely across multiple processes.\n   ```python\n   from multiprocessing import Queue\n   queue = Queue()\n   queue.put(item)  # Add item\n   item = queue.get()  # Retrieve item\n   ```\n\n2. **`multiprocessing.Pipe`:**\n   - A method to create a two-way communication channel between two processes. Each end of the pipe can send and receive messages.\n   ```python\n   from multiprocessing import Pipe\n   parent_conn, child_conn = Pipe()\n   parent_conn.send(data)  # Send data\n   data = child_conn.recv()  # Receive data\n   ```\n\n3. **`multiprocessing.Manager`:**\n   - A manager object allows you to create shared objects like lists, dictionaries, and values that can be safely accessed by multiple processes.\n   ```python\n   from multiprocessing import Manager\n   manager = Manager()\n   shared_list = manager.list()  # Shared list\n   ```\n\n4. **`multiprocessing.Lock`:**\n   - Similar to `threading.Lock`, this lock is used to prevent simultaneous access to shared resources by multiple processes.\n   ```python\n   from multiprocessing import Lock\n   lock = Lock()\n   with lock:\n       # Critical section\n   ```\n\n5. **`multiprocessing.Event`:**\n   - Like `threading.Event`, it allows processes to wait for a flag to be set.\n   ```python\n   from multiprocessing import Event\n   event = Event()\n   event.set()  # Set the event",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#6. Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for doing so\n#ans.\nHandling exceptions in concurrent programs is crucial for several reasons:\n\n### Importance of Exception Handling in Concurrent Programs\n\n1. **Preventing Program Crashes:**\n   - Uncaught exceptions in one thread or process can lead to the termination of that thread or process, potentially causing the entire application to crash or enter an inconsistent state.\n\n2. **Maintaining Data Integrity:**\n   - Exceptions can occur during operations that modify shared data. Properly handling these exceptions is vital to avoid data corruption or inconsistency.\n\n3. **Resource Management:**\n   - Concurrent programs often involve acquiring and releasing resources (like locks, files, or network connections). If exceptions are not handled, resources may remain locked or unreleased, leading to deadlocks or resource leaks.\n\n4. **Debugging and Logging:**\n   - Proper exception handling allows for better debugging and logging. This helps developers understand issues that arise in specific threads or processes and facilitates easier troubleshooting.\n\n5. **User Experience:**\n   - In applications with user interfaces, unhandled exceptions can lead to poor user experiences, such as freezes or crashes. Handling exceptions gracefully allows for better user feedback and recovery options.\n\n### Techniques for Handling Exceptions in Concurrent Programs\n\n1. **Try-Except Blocks:**\n   - Surround potentially problematic code with try-except blocks to catch and handle exceptions locally.\n\n   try:\n       # Code that may raise an exception\n   except Exception as e:\n       # Handle the exception\n   ```\n\n2. **Thread-Specific Exception Handling:**\n   - For threads, you can define exception handling within the thread's target function. This allows each thread to manage its own exceptions.\n\n   def thread_function():\n       try:\n           # Code that may raise an exception\n       except Exception as e:\n           print(f\"Error in thread: {e}\")\n   ```\n\n3. **Process-Specific Exception Handling:**\n   - In multiprocessing, since each process has its own memory space, exceptions need to be handled within the process. You can use try-except blocks in the target function for the process.\n\n   from multiprocessing import Process\n\n   def process_function():\n       try:\n           # Code that may raise an exception\n       except Exception as e:\n           print(f\"Error in process: {e}\")\n\n   p = Process(target=process_function)\n   p.start()\n   ```\n\n4. **Using a Custom Exception Hook:**\n   - For threads, you can set a custom exception hook to handle uncaught exceptions globally. This can be useful for logging or cleanup.\n\n   import sys\n   import threading\n\n   def handle_exception(exc_type, exc_value, exc_traceback):\n       if issubclass(exc_type, KeyboardInterrupt):\n           sys.__excepthook__(exc_type, exc_value, exc_traceback)\n           return\n       # Handle or log the exception\n       print(f\"Uncaught exception: {exc_value}\")\n\n   sys.excepthook = handle_exception\n   ```\n\n5. **Returning Exceptions:**\n   - In concurrent programming, especially when using futures or thread pools, you can return exceptions from tasks and handle them when retrieving results.\n\n   from concurrent.futures import ThreadPoolExecutor\n\n   def task():\n       raise ValueError(\"An error occurred\")\n\n   with ThreadPoolExecutor() as executor:\n       future = executor.submit(task)\n       try:\n           result = future.result()  # This will raise the exception if it occurred\n       except Exception as e:\n           print(f\"Task raised an exception: {e}\")\n \n\n6. **Logging:**\n   - Implement logging to capture exceptions for later analysis, especially in production environments. Use Python's built-in `logging` module to log exceptions and errors.\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently. Use concurrent.futures.ThreadPoolExecutor to manage the threads\n#ans.\nimport concurrent.futures\nimport math\n\ndef factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    return math.factorial(n)\n\ndef main():\n    numbers = range(1, 11)  # Numbers from 1 to 10\n    results = {}\n\n    # Use ThreadPoolExecutor to manage threads\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        # Submit tasks to the executor\n        futures = {executor.submit(factorial, n): n for n in numbers}\n\n        # Collect results as they complete\n        for future in concurrent.futures.as_completed(futures):\n            number = futures[future]\n            try:\n                result = future.result()  # Get the result of the computation\n                results[number] = result\n            except Exception as e:\n                print(f\"Error calculating factorial of {number}: {e}\")\n\n    # Print the results\n    for number, result in results.items():\n        print(f\"Factorial of {number} is {result}\")\n\nif __name__ == \"__main__\":\n    main()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in  parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8 processes)\n#ans.\nimport multiprocessing\nimport time\n\ndef square(n):\n    \"\"\"Return the square of a number.\"\"\"\n    return n * n\n\ndef compute_squares(pool_size):\n    \"\"\"Compute squares using a pool of processes and measure the time taken.\"\"\"\n    numbers = range(1, 11)  # Numbers from 1 to 10\n\n    # Start timing\n    start_time = time.time()\n\n    # Create a pool of processes\n    with multiprocessing.Pool(processes=pool_size) as pool:\n        results = pool.map(square, numbers)\n\n    # End timing\n    end_time = time.time()\n\n    return results, end_time - start_time\n\ndef main():\n    pool_sizes = [2, 4, 8]  # Different pool sizes\n    for size in pool_sizes:\n        results, duration = compute_squares(size)\n        print(f\"Pool size: {size}, Results: {results}, Time taken: {duration:.4f} seconds\")\n\nif __name__ == \"__main__\":\n    main()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}