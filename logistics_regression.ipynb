{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "name": ""
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "404370a1-98c1-4023-8c39-ae9c89113d9e",
      "cell_type": "code",
      "source": "#1 What is Logistic Regression, and how does it differ from Linear Regression.\n#ans **Logistic Regression vs. Linear Regression**  \n\n# **1. Logistic Regression**  \nLogistic Regression is a statistical method used for **classification problems** where the output is categorical (e.g., Yes/No, 0/1, Spam/Not Spam). Instead of predicting a continuous value, it predicts the probability that a given input belongs to a particular class using the **Sigmoid function**.  \n\n- **Formula:**  \n  \\[\n  P(Y=1) = \\frac{1}{1 + e^{-(b_0 + b_1X_1 + b_2X_2 + ... + b_nX_n)}}\n  \\]\n- The output is a probability between **0 and 1**, which is then converted into a class (e.g., if \\( P(Y) > 0.5 \\), classify as 1).  \n\n#### **2. Linear Regression**  \nLinear Regression is used for **regression problems**, where the output is a continuous value (e.g., predicting salary, house price). It finds the best-fit line that minimizes the difference between actual and predicted values.  \n\n- **Formula:**  \n  \\[\n  Y = b_0 + b_1X_1 + b_2X_2 + ... + b_nX_n\n  \\]\n- The output is a continuous numeric value.  \n\n### **Key Differences:**  \n\n| Feature                | Logistic Regression      | Linear Regression  |\n|------------------------|------------------------|--------------------|\n| **Type of Problem**    | Classification (Yes/No, 0/1) | Regression (Continuous output) |\n| **Output**             | Probability (0 to 1) ‚Üí Categorical | Continuous numerical value |\n| **Mathematical Function** | Sigmoid Function | Linear Equation |\n| **Error Function**     | Log Loss (Cross-Entropy Loss) | Mean Squared Error (MSE)\n|\n| **Interpretation**     | Predicts the probability of a class | Predicts exact numerical value |\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "97520f68-bd42-4e3e-bfda-387ec26d3305",
      "cell_type": "code",
      "source": "#2 What is the mathematical equation of Logistic Regression.\n#ans.The mathematical equation of **Logistic Regression** is derived from the **linear regression equation** but passed through a **sigmoid function** to constrain the output between 0 and 1.\n\n### **1. Linear Regression Equation**  \nA linear model is given by:  \n\\[\nZ = b_0 + b_1X_1 + b_2X_2 + ... + b_nX_n\n\\]\nwhere:  \n- \\( Z \\) is the linear combination of input features.\n- \\( X_1, X_2, ..., X_n \\) are independent variables (features).\n- \\( b_0 \\) is the intercept (bias).\n- \\( b_1, b_2, ..., b_n \\) are coefficients (weights).\n\n### **2. Applying the Sigmoid Function**  \nTo convert the linear regression output into a probability between **0 and 1**, we apply the **Sigmoid function**:\n\n\\[\nP(Y=1) = \\frac{1}{1 + e^{-Z}}\n\\]\n\nSubstituting \\( Z \\):\n\n\\[\nP(Y=1) = \\frac{1}{1 + e^{-(b_0 + b_1X_1 + b_2X_2 + ... + b_nX_n)}}\n\\]\n\n### **3. Decision Boundary**  \n- If \\( P(Y=1) > 0.5 \\), classify as **1**  \n- If \\( P(Y=1) \\leq 0.5 \\), classify as **0**\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "22c722f4-9cb0-4d4d-9068-f23ff4cc4b59",
      "cell_type": "code",
      "source": "#3 Why do we use the Sigmoid function in Logistic Regression.\n#ans. ### **Why Do We Use the Sigmoid Function in Logistic Regression?**  \n\nThe **Sigmoid function** is used in Logistic Regression because it helps transform any real-valued number into a **probability between 0 and 1**, which is essential for classification tasks.  \n\n### **1. Definition of Sigmoid Function**  \nThe Sigmoid function is given by:  \n\n\\[\nS(Z) = \\frac{1}{1 + e^{-Z}}\n\\]\n\nwhere \\( Z = b_0 + b_1X_1 + b_2X_2 + ... + b_nX_n \\) is the linear equation.\n\n### **2. Why is it Used?**  \n‚úÖ **Probability Output:**  \n   - The Sigmoid function converts raw scores into probabilities between **0 and 1**, making it suitable for binary classification.  \n\n‚úÖ **Decision Boundary for Classification:**  \n   - If \\( S(Z) > 0.5 \\), classify as **1**  \n   - If \\( S(Z) \\leq 0.5 \\), classify as **0**  \n\n‚úÖ **Differentiability (Gradient Descent Friendly):**  \n   - The function is **smooth and differentiable**, making it easy to optimize using **gradient descent**.  \n\n‚úÖ **Handles Outliers:**  \n   - The exponential function ensures that extreme values of \\( Z \\) (very high or very low) are squashed between **0 and 1**, preventing large deviations.\n\n### **3. Graphical Representation**  \n- The Sigmoid curve is **S-shaped**, with values approaching **0** for large negative inputs and **1** for large positive inputs.  \n- At \\( Z = 0 \\), \\( S(Z) = 0.5 \\), which acts as a natural threshold.  \n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "b595aa04-6ff5-46ef-9152-3a60b98e648c",
      "cell_type": "code",
      "source": "#4.#C What is the cost function of Logistic Regression\n#### **Cost Function of Logistic Regression**  \n\nIn Logistic Regression, we use the **Log Loss (Logistic Loss)** or **Binary Cross-Entropy Loss** as the cost function instead of Mean Squared Error (MSE), because the Sigmoid function is non-linear, and MSE would lead to a non-convex loss function, making optimization difficult.\n\n---\n\n### **1. Binary Cross-Entropy (Log Loss) Formula**  \nFor a binary classification problem where \\( Y \\in \\{0,1\\} \\) and the predicted probability is \\( \\hat{Y} = P(Y=1) \\), the cost function is:\n\n\\[\nJ(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ Y^{(i)} \\log \\hat{Y}^{(i)} + (1 - Y^{(i)}) \\log (1 - \\hat{Y}^{(i)}) \\right]\n\\]\n\nwhere:\n- \\( m \\) = number of training examples  \n- \\( Y^{(i)} \\) = actual class label (0 or 1) for the \\( i \\)th sample  \n- \\( \\hat{Y}^{(i)} \\) = predicted probability for class 1  \n- \\( \\log \\) ensures high confidence correct predictions have low cost  \n- The negative sign ensures the function is minimized when predictions are accurate  \n\n---\n\n### **2. Intuition Behind Log Loss**  \n- If **\\( Y = 1 \\)**: The loss simplifies to \\( -\\log (\\hat{Y}) \\), meaning high probability predictions (\\( \\hat{Y} \\approx 1 \\)) result in lower loss.  \n- If **\\( Y = 0 \\)**: The loss simplifies to \\( -\\log (1 - \\hat{Y}) \\), meaning lower probability predictions for class 1 (\\( \\hat{Y} \\approx 0 \\)) result in lower loss.  \n\n---\n\n### **3. Why Not Mean Squared Error (MSE)?**  \n- MSE creates a **non-convex function** for logistic regression, leading to multiple local minima.  \n- Log Loss is **convex**, ensuring efficient optimization with **Gradient Descent**.  \n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3eb07b83-1b8d-4df3-90c6-4a1c565b2dd2",
      "cell_type": "code",
      "source": "#5.What is Regularization in Logistic Regression? Why is it needed.\n#ans.### **Regularization in Logistic Regression**  \n\n**Regularization** is a technique used to **prevent overfitting** in Logistic Regression by adding a penalty term to the cost function. It helps control the complexity of the model by discouraging large coefficients (weights), ensuring better generalization to unseen data.\n\n---\n\n### **1. Why is Regularization Needed?**  \n‚úÖ **Prevents Overfitting:** If the model is too complex (too many features or large weights), it memorizes the training data instead of generalizing well to new data.  \n\n‚úÖ **Reduces Variance:** Regularization reduces model variance, ensuring it performs well on both training and test data.  \n\n‚úÖ **Controls Large Coefficients:** Without regularization, the logistic regression model might assign excessively high values to coefficients, leading to unstable predictions.\n\n---\n\n### **2. Types of Regularization**  \nRegularization is applied by adding a penalty term to the **Log Loss function**.\n\n#### **A. L2 Regularization (Ridge Regression)**\n- Adds a **squared sum of weights** to the cost function.\n- Helps in **shrinking coefficients** without making them exactly zero.\n\n\\[\nJ(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ Y^{(i)} \\log \\hat{Y}^{(i)} + (1 - Y^{(i)}) \\log (1 - \\hat{Y}^{(i)}) \\right] + \\frac{\\lambda}{2m} \\sum_{j=1}^{n} \\theta_j^2\n\\]\n\n‚úÖ **Used by default in Logistic Regression (e.g., in Scikit-learn)**  \n‚úÖ **Prevents large coefficients while keeping all features**  \n\n---\n\n#### **B. L1 Regularization (Lasso Regression)**\n- Adds an **absolute sum of weights** to the cost function.\n- Helps in **feature selection** by shrinking some coefficients to **exactly zero**.\n\n\\[\nJ(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ Y^{(i)} \\log \\hat{Y}^{(i)} + (1 - Y^{(i)}) \\log (1 - \\hat{Y}^{(i)}) \\right] + \\frac{\\lambda}{m} \\sum_{j=1}^{n} |\\theta_j|\n\\]\n\n‚úÖ **Used when feature selection is needed**  \n‚úÖ **Removes less important features automatically**  \n\n---\n\n### **3. Choosing Between L1 and L2**\n- **L2 (Ridge):** If all features are important but should have controlled impact.  \n- **L1 (Lasso):** If you want **automatic feature selection** by removing irrelevant features.  \n- **Elastic Net:** A mix of **L1 and L2** regularization, useful when features are correlated.\n\n---\n\n### **4. Hyperparameter \\( \\lambda \\) (Regularization Strength)**\n- **High \\( \\lambda \\)** ‚Üí More regularization (simpler model, avoids overfitting).  \n- **Low \\( \\lambda \\)** ‚Üí Less regularization (complex model, risk of overfitting).  \n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f5e014f5-81ac-4a7a-866b-ecb52baaf6db",
      "cell_type": "code",
      "source": "#6. Explain the difference between Lasso, Ridge, and Elastic Net regression\n#ans.### **Difference Between Lasso, Ridge, and Elastic Net Regression**  \n\nRegularization techniques like **Lasso, Ridge, and Elastic Net** are used to **prevent overfitting** by adding a penalty term to the cost function, controlling the size of model coefficients. The key difference lies in **how they penalize** the coefficients.  \n\n---\n\n## **1. Ridge Regression (L2 Regularization)**\n‚úÖ **Adds the sum of squared coefficients as a penalty**  \n\n\\[\nJ(\\theta) = \\text{MSE} + \\lambda \\sum_{j=1}^{n} \\theta_j^2\n\\]\n\nüìå **Key Features:**  \n- Shrinks **all coefficients** but does not make any exactly **zero**.  \n- Helps when **all features are important** but need controlled influence.  \n- Works well when features are **highly correlated** (prevents overfitting).  \n\nüìå **Use Case:**  \n- When **all variables contribute** and you don‚Äôt want to remove any features.  \n\n---\n\n## **2. Lasso Regression (L1 Regularization)**\n‚úÖ **Adds the sum of absolute values of coefficients as a penalty**  \n\n\\[\nJ(\\theta) = \\text{MSE} + \\lambda \\sum_{j=1}^{n} |\\theta_j|\n\\]\n\nüìå **Key Features:**  \n- Shrinks some coefficients **completely to zero**, effectively performing **feature selection**.  \n- Good for datasets with **many irrelevant features**.  \n- Can struggle with **highly correlated features** (randomly picks one).  \n\nüìå **Use Case:**  \n- When you want **automatic feature selection** and a **sparse model** (some coefficients = 0).  \n\n---\n\n## **3. Elastic Net Regression (L1 + L2 Regularization)**\n‚úÖ **Combines L1 and L2 regularization**  \n\n\\[\nJ(\\theta) = \\text{MSE} + \\lambda_1 \\sum_{j=1}^{n} |\\theta_j| + \\lambda_2 \\sum_{j=1}^{n} \\theta_j^2\n\\]\n\nüìå **Key Features:**  \n- **Balances Ridge and Lasso**, allowing both **feature selection** and **weight shrinking**.  \n- Works well when features are **highly correlated**.  \n- Prevents Lasso‚Äôs issue of selecting only one feature among correlated features.  \n\nüìå **Use Case:**  \n- When you need both **regularization and feature selection** but have correlated features.  \n\n---\n\n## **Comparison Table**\n\n| Feature           | Ridge Regression (L2) | Lasso Regression (L1) | Elastic Net (L1 + L2) |\n|------------------|--------------------|--------------------|-------------------|\n| **Penalty Term**  | \\( \\sum \\theta^2 \\) (Squared) | \\( \\sum |\\theta| \\) (Absolute) | Combination of both |\n| **Effect on Coefficients** | Shrinks but keeps all | Shrinks, some become **zero** | Shrinks, some become **zero** |\n| **Feature Selection?** | ‚ùå No | ‚úÖ Yes | ‚úÖ Yes (better than Lasso) |\n| **Handles Multicollinearity?** | ‚úÖ Yes | ‚ùå No (randomly selects one) | ‚úÖ Yes |\n| **Use Case** | When all features are useful | When feature selection is needed | When features are correlated and selection is needed |\n\n---\n\n### **Conclusion**\n- Use **Ridge (L2)** if **all features matter** and you just want to **control their impact**.  \n- Use **Lasso (L1)** if you want **automatic feature selection**.  \n- Use **Elastic Net** if you need **feature selection + multicollinearity handling**.  \n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "631c6f5b-3e0d-4e08-b417-587de4a27c1e",
      "cell_type": "code",
      "source": "#7.When should we use Elastic Net instead of Lasso or Ridge.\nElastic Net is a combination of **Lasso (L1 regularization)** and **Ridge (L2 regularization)** and is useful in situations where neither Lasso nor Ridge alone performs optimally. Here‚Äôs when to use Elastic Net instead of just Lasso or Ridge:\n\n### 1. **When Features are Highly Correlated**\n   - Lasso tends to select only one feature among a group of correlated features and ignores the rest.\n   - Ridge spreads the weights across all correlated features but does not perform feature selection.\n   - **Elastic Net combines both approaches**, selecting groups of correlated features while also shrinking coefficients to prevent overfitting.\n\n### 2. **When Lasso is Too Aggressive in Feature Selection**\n   - Lasso may force some coefficients to zero, removing important features.\n   - If you suspect that multiple features contribute to the outcome, Elastic Net ensures **better stability** in feature selection.\n\n### 3. **When You Have More Features Than Observations (High-Dimensional Data)**\n   - In cases where the number of features **(p) exceeds the number of samples (n)** (e.g., genetics, text data), Lasso alone might fail, and Ridge might be too weak in feature selection.\n   - **Elastic Net performs well in high-dimensional settings** by balancing feature selection and coefficient shrinkage.\n\n### 4. **When You Want a Balance Between Lasso and Ridge**\n   - Elastic Net introduces a mixing parameter **Œ± (alpha)** to control the ratio between Lasso and Ridge penalties.\n   - If **Œ± = 1**, it behaves like Lasso.\n   - If **Œ± = 0**, it behaves like Ridge.\n   - You can **tune Œ±** to find the best mix for your dataset.\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f646ca78-726f-49f7-a949-b8096970d659",
      "cell_type": "code",
      "source": "#8. What is the impact of the regularization parameter (Œª) in Logistic Regression.\n#ans.In **Logistic Regression**, the regularization parameter **Œª (lambda)** controls the strength of regularization applied to the model. It impacts the model‚Äôs performance, complexity, and generalization ability. Here‚Äôs how **Œª** affects Logistic Regression:\n\n### **1. Controlling Overfitting and Underfitting**\n- **Large Œª (High Regularization)**  \n  - Increases the penalty on large coefficients, forcing them to be smaller.  \n  - Prevents overfitting by reducing model complexity.  \n  - Can lead to **underfitting** if Œª is too high, making the model too simple and less accurate.\n\n- **Small Œª (Low Regularization)**  \n  - Allows the model to learn more from the data.  \n  - If too small, the model may overfit, capturing noise rather than general trends.  \n\n### **2. Impact on Coefficients**\n- **Higher Œª ‚Üí Smaller Coefficients:** Shrinks feature weights closer to zero.  \n- **Lower Œª ‚Üí Larger Coefficients:** Allows higher variance in feature weights.  \n- **Extreme Œª ‚Üí Zero Coefficients (L1 Regularization):** Lasso (L1) can shrink some coefficients **exactly to zero**, effectively performing feature selection.\n\n### **3. Model Generalization**\n- A well-tuned **Œª** ensures the model generalizes well to unseen data.  \n- **Cross-validation** is often used to find the optimal Œª that minimizes validation error.\n\n### **4. Types of Regularization in Logistic Regression**\n- **L1 Regularization (Lasso)**: Encourages sparsity (some coefficients become zero).  \n- **L2 Regularization (Ridge)**: Shrinks coefficients but keeps them small, preventing extreme weights.  \n- **Elastic Net**: A mix of L1 and L2 regularization.\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "972a6cf3-3dc5-4d7c-ace5-126e592995f1",
      "cell_type": "code",
      "source": "#9 What are the key assumptions of Logistic Regression.\n#ans.Logistic Regression is a widely used classification algorithm, but it relies on certain key assumptions for optimal performance. Here are the key assumptions:\n\n### **1. The Relationship Between Independent and Dependent Variables is Log-Linear**  \n   - Logistic Regression assumes that the **log-odds (logit transformation)** of the dependent variable has a **linear relationship** with the independent variables.  \n   - Unlike Linear Regression, it does **not assume a direct linear relationship** between the independent and dependent variables.\n\n### **2. No Multicollinearity**  \n   - Independent variables should **not be highly correlated** with each other.  \n   - High correlation (multicollinearity) can make coefficient estimation unstable.  \n   - **Solution:** Use **Variance Inflation Factor (VIF)** or **Principal Component Analysis (PCA)** to detect and resolve multicollinearity.\n\n### **3. Independent Observations**  \n   - Observations should be **independent of each other** (i.e., no hidden relationships in the data).  \n   - If observations are correlated (e.g., time-series data), methods like **Generalized Estimating Equations (GEE)** or **Mixed Effects Models** should be considered.\n\n### **4. No Strong Outliers**  \n   - Logistic Regression is sensitive to outliers, as they can distort coefficient estimates.  \n   - **Solution:** Use techniques like **IQR (Interquartile Range), Boxplots, or Winsorization** to detect and handle outliers.\n\n### **5. Large Sample Size (Especially for Maximum Likelihood Estimation - MLE)**  \n   - Logistic Regression uses **Maximum Likelihood Estimation (MLE)** for parameter estimation, which works best with **a large number of observations**.  \n   - Small sample sizes can lead to unreliable coefficient estimates.\n\n### **6. No Perfect Separation**  \n   - If one class is perfectly separable from another, Logistic Regression may struggle because **MLE will not converge**.  \n   - **Solution:** Use **Regularization (L1/L2), Collect More Data, or Use a Different Model (e.g., Decision Trees, SVM).**\n\n### **7. The Dependent Variable is Binary (For Standard Logistic Regression)**  \n   - Logistic Regression assumes the target variable is **binary (0 or 1)** for standard applications.  \n   - For multi-class classification, **Multinomial Logistic Regression** should be used.\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2dbb70dc-219d-469b-bf50-82088c059b74",
      "cell_type": "code",
      "source": "#10 What are some alternatives to Logistic Regression for classification tasks.\n#ans.If Logistic Regression isn't the best fit for your classification problem, several alternative models can be considered, depending on factors like data size, feature relationships, and interpretability. Here are some key alternatives:\n\n---\n\n### **1. Decision Trees**\n   - **Why?** Handles **nonlinear relationships** and is easy to interpret.\n   - **Pros:** No need for feature scaling, works well with categorical data.\n   - **Cons:** Prone to overfitting (unless pruned or regularized).\n   - **Best for:** Small to medium-sized datasets, interpretability-focused applications.\n\n---\n\n### **2. Random Forest**\n   - **Why?** An ensemble of Decision Trees that improves generalization.\n   - **Pros:** Reduces overfitting, works well with missing data.\n   - **Cons:** Less interpretable, computationally expensive.\n   - **Best for:** Complex datasets with many features and nonlinear relationships.\n\n---\n\n### **3. Support Vector Machines (SVM)**\n   - **Why?** Finds an optimal decision boundary (hyperplane).\n   - **Pros:** Works well with high-dimensional data, robust to outliers.\n   - **Cons:** Computationally expensive for large datasets, sensitive to hyperparameters.\n   - **Best for:** Small to medium-sized datasets with **clear class separation**.\n\n---\n\n### **4. k-Nearest Neighbors (k-NN)**\n   - **Why?** A simple, non-parametric method that classifies based on similarity.\n   - **Pros:** No training time, intuitive.\n   - **Cons:** Computationally expensive at inference, sensitive to irrelevant features.\n   - **Best for:** Small datasets with well-defined clusters.\n\n---\n\n### **5. Na√Øve Bayes**\n   - **Why?** A probabilistic model based on **Bayes‚Äô Theorem**.\n   - **Pros:** Works well with text classification, fast, and requires little data.\n   - **Cons:** Assumes feature independence (which is often unrealistic).\n   - **Best for:** **Text classification (spam detection, sentiment analysis)**.\n\n---\n\n### **6. Gradient Boosting (XGBoost, LightGBM, CatBoost)**\n   - **Why?** Boosting algorithms that sequentially improve predictions.\n   - **Pros:** Highly accurate, works with both structured and unstructured data.\n   - **Cons:** Computationally expensive, requires careful tuning.\n   - **Best for:** Large datasets with complex relationships.\n\n---\n\n### **7. Neural Networks (Deep Learning)**\n   - **Why?** Captures complex patterns and works well with big data.\n   - **Pros:** Handles **nonlinearity** and large feature sets.\n   - **Cons:** Requires large amounts of data, less interpretable.\n   - **Best for:** Image recognition, speech processing, NLP.\n\n---\n\n### **How to Choose the Right Model?**\n| Scenario | Best Alternative |\n|-----------|----------------|\n| High-dimensional data | SVM, Gradient Boosting |\n| Nonlinear relationships | Random Forest, XGBoost |\n| Interpretability required | Decision Tree, Logistic Regression |\n| Small dataset | k-NN, Na√Øve Bayes |\n| Large dataset | Neural Networks, XGBoost |\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "32c589ce-ac03-48e7-b0f0-99c39b15b55c",
      "cell_type": "code",
      "source": "#11. What are Classification Evaluation Metrics.\n### **Classification Evaluation Metrics**  \nWhen evaluating a classification model, we use different metrics to measure its performance. The choice of the right metric depends on the problem (e.g., balanced vs. imbalanced classes). Below are key classification evaluation metrics:\n\n---\n\n### **1. Accuracy**  \nüìå **Formula:**  \n\\[\nAccuracy = \\frac{TP + TN}{TP + TN + FP + FN}\n\\]  \n‚úÖ **Good for:** Balanced datasets.  \n‚ùå **Not ideal for:** Imbalanced datasets (e.g., detecting rare diseases).  \n\n---\n\n### **2. Precision (Positive Predictive Value - PPV)**  \nüìå **Formula:**  \n\\[\nPrecision = \\frac{TP}{TP + FP}\n\\]  \n‚úÖ **Good for:** When **false positives (FP)** need to be minimized (e.g., spam detection).  \n‚ùå **Not ideal for:** When false negatives are more critical.  \n\n---\n\n### **3. Recall (Sensitivity, True Positive Rate - TPR)**  \nüìå **Formula:**  \n\\[\nRecall = \\frac{TP}{TP + FN}\n\\]  \n‚úÖ **Good for:** When **false negatives (FN)** are costly (e.g., cancer detection).  \n‚ùå **Not ideal for:** Situations where precision is more important.  \n\n---\n\n### **4. F1-Score (Harmonic Mean of Precision and Recall)**  \nüìå **Formula:**  \n\\[\nF1 = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall}\n\\]  \n‚úÖ **Good for:** Imbalanced datasets (balances precision and recall).  \n‚ùå **Not ideal for:** Cases where one metric (precision or recall) is much more important.  \n\n---\n\n### **5. Specificity (True Negative Rate - TNR)**  \nüìå **Formula:**  \n\\[\nSpecificity = \\frac{TN}{TN + FP}\n\\]  \n‚úÖ **Good for:** When correctly identifying **negative cases** is important (e.g., fraud detection).  \n\n---\n\n### **6. ROC Curve (Receiver Operating Characteristic Curve)**  \nüìå **What it Shows:**  \n- Plots **True Positive Rate (Recall) vs. False Positive Rate (FPR)**.  \n- Helps visualize the model's ability to distinguish between classes.  \n\n‚úÖ **Good for:** Comparing models and tuning classification thresholds.  \n\n---\n\n### **7. AUC-ROC (Area Under the ROC Curve)**  \nüìå **What it Represents:**  \n- AUC = **1.0** ‚Üí Perfect model  \n- AUC = **0.5** ‚Üí Random guessing  \n- AUC closer to 1 means a **better classifier**.  \n\n‚úÖ **Good for:** Evaluating model performance across different thresholds.  \n\n---\n\n### **8. PR Curve (Precision-Recall Curve)**  \nüìå **What it Shows:**  \n- Plots **Precision vs. Recall** at different thresholds.  \n- More useful for **imbalanced datasets** than ROC.  \n\n‚úÖ **Good for:** When focusing on precision-recall trade-offs.  \n\n---\n\n### **9. Log Loss (Logarithmic Loss / Cross-Entropy Loss)**  \nüìå **Formula:**  \n\\[\nLogLoss = -\\frac{1}{N} \\sum_{i=1}^{N} \\left[y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i)\\right]\n\\]  \n‚úÖ **Good for:** Models that output probabilities (e.g., logistic regression, neural networks).  \n‚ùå **Not ideal for:** Hard classification tasks (where only labels are needed, not probabilities).  \n\n---\n\n### **Choosing the Right Metric**\n| **Scenario** | **Best Metric** |\n|-------------|---------------|\n| Balanced dataset | Accuracy |\n| Imbalanced dataset | Precision, Recall, F1-Score, PR Curve |\n| Minimize false positives | Precision (e.g., spam detection) |\n| Minimize false negatives | Recall (e.g., disease detection) |\n| Model comparison | AUC-ROC, PR Curve |\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "8bc05b72-610e-4226-a994-59268b898dfe",
      "cell_type": "code",
      "source": "#12. How does class imbalance affect Logistic Regression.\n### **How Class Imbalance Affects Logistic Regression**  \n\nClass imbalance occurs when one class significantly outnumbers the other in a dataset (e.g., fraud detection, rare disease diagnosis). This imbalance can negatively impact **Logistic Regression** in several ways:\n\n---\n\n### **1. Biased Model Predictions**  \n- **Logistic Regression assumes equal class distribution**, so it **learns to favor the majority class**.  \n- This leads to high accuracy but poor performance on the minority class.  \n\nüîπ **Example:**  \n- Suppose a dataset has **95% class A** and **5% class B**.  \n- If the model always predicts class A, it gets **95% accuracy**, but class B is completely ignored.  \n\n---\n\n### **2. Poor Precision and Recall for the Minority Class**  \n- The model **struggles to detect the minority class**, leading to:  \n  - **Low Recall (High False Negatives)** ‚Üí Misses many minority class instances.  \n  - **Low Precision (High False Positives)** ‚Üí Predicts some majority class instances as the minority class incorrectly.  \n\n---\n\n### **3. Misleading Accuracy Metric**  \n- Accuracy becomes **misleading** because it is dominated by the majority class.  \n- **Solution:** Use **F1-score, Precision-Recall (PR) Curve, or AUC-ROC** instead of accuracy.  \n\n---\n\n### **4. Poor Probability Estimates**  \n- The predicted probabilities tend to be **biased toward the majority class**.  \n- Logistic Regression uses **Maximum Likelihood Estimation (MLE)**, which assumes a balanced dataset.  \n- This leads to **poor threshold calibration** for classification.  \n\n---\n\n## **How to Handle Class Imbalance in Logistic Regression?**  \n\n### ‚úÖ **1. Resampling Techniques**  \n- **Oversampling (e.g., SMOTE - Synthetic Minority Over-sampling Technique)**  \n  - Generates synthetic samples for the minority class to balance the dataset.  \n- **Undersampling**  \n  - Reduces the number of majority class samples.  \n- **Hybrid Approach (SMOTE + Undersampling)**  \n  - A mix of both techniques to avoid overfitting.  \n\n---\n\n### ‚úÖ **2. Adjusting Class Weights**  \n- Set **higher weights for the minority class** during training.  \n- In **Scikit-learn**, use:  \n  ```python\n  from sklearn.linear_model import LogisticRegression\n  model = LogisticRegression(class_weight='balanced')\n  ```\n\n---\n\n### ‚úÖ **3. Changing Decision Threshold**  \n- By default, Logistic Regression classifies based on a **0.5 threshold**.  \n- Lowering the threshold can **increase recall** for the minority class.  \n- **How to find the best threshold?**  \n  - Use the **Precision-Recall curve** or **ROC curve**.  \n\n---\n\n### ‚úÖ **4. Alternative Algorithms**  \n- **Tree-based models** (Random Forest, XGBoost) handle imbalance better.  \n- **Anomaly detection models** work well when the minority class is extremely rare.  \n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "628759c1-6208-4c64-aac6-476069c1311f",
      "cell_type": "code",
      "source": "#13. What is Hyperparameter Tuning in Logistic Regression.\n#ans.### **Hyperparameter Tuning in Logistic Regression**  \n\n**Hyperparameter tuning** in Logistic Regression involves optimizing the model‚Äôs parameters to improve performance. Unlike model parameters (like coefficients), hyperparameters are set **before** training and need tuning for the best results.\n\n---\n\n## **Key Hyperparameters in Logistic Regression**\n### ‚úÖ **1. Regularization Parameter (Œª or C)**\n- Controls the strength of **L1 (Lasso) or L2 (Ridge) regularization**.\n- In **Scikit-learn**, the hyperparameter is **C**, which is the **inverse** of Œª:\n  \\[\n  C = \\frac{1}{\\lambda}\n  \\]\n- **Higher C (low Œª) ‚Üí Less regularization** (risk of overfitting).\n- **Lower C (high Œª) ‚Üí More regularization** (risk of underfitting).\n\nüîπ **Example:**\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\nlog_reg = LogisticRegression(penalty='l2', solver='liblinear')\ngrid_search = GridSearchCV(log_reg, param_grid, cv=5, scoring='accuracy')\ngrid_search.fit(X_train, y_train)\nprint(\"Best C:\", grid_search.best_params_)\n```\n\n---\n\n### ‚úÖ **2. Regularization Type (`penalty`)**\n- **L1 (Lasso) ‚Üí Feature selection (sparse model)**.\n- **L2 (Ridge) ‚Üí Prevents large coefficients (no feature elimination)**.\n- **Elastic Net (Mix of L1 and L2) ‚Üí Balances feature selection and shrinkage**.\n\nüîπ **Example:**\n```python\nparam_grid = {'penalty': ['l1', 'l2'], 'C': [0.01, 0.1, 1, 10]}\nlog_reg = LogisticRegression(solver='liblinear')\ngrid_search = GridSearchCV(log_reg, param_grid, cv=5)\ngrid_search.fit(X_train, y_train)\n```\n\n---\n\n### ‚úÖ **3. Solver (`solver`)**\n- Different optimization algorithms for training:\n  - `'liblinear'` ‚Üí Good for small datasets (supports L1 & L2).\n  - `'lbfgs'` ‚Üí Default, good for large datasets (L2 only).\n  - `'saga'` ‚Üí Best for large datasets with L1/L2 or Elastic Net.\n\nüîπ **Example:**\n```python\nparam_grid = {'solver': ['liblinear', 'lbfgs', 'saga']}\n```\n\n---\n\n### ‚úÖ **4. Class Weight (`class_weight`)**\n- Handles **class imbalance** by assigning different weights to classes.\n- `'balanced'` automatically adjusts weights based on class distribution.\n\nüîπ **Example:**\n```python\nlog_reg = LogisticRegression(class_weight='balanced')\n```\n\n---\n\n### ‚úÖ **5. Maximum Iterations (`max_iter`)**\n- Controls the number of iterations for convergence.\n- Increase if the model **fails to converge**.\n\nüîπ **Example:**\n```python\nlog_reg = LogisticRegression(max_iter=500)\n```\n\n---\n\n## **Hyperparameter Tuning Methods**\n### üîπ **1. Grid Search (Exhaustive Search)**\n- Tests all possible combinations.\n- **Computationally expensive** for large datasets.\n\n```python\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'penalty': ['l1', 'l2']}\ngrid_search = GridSearchCV(LogisticRegression(solver='liblinear'), param_grid, cv=5)\ngrid_search.fit(X_train, y_train)\n\nprint(\"Best Parameters:\", grid_search.best_params_)\n```\n\n---\n\n### üîπ **2. Randomized Search (Faster Alternative)**\n- Randomly selects hyperparameter values instead of testing all combinations.\n- **Faster than Grid Search**, but may miss the best combination.\n\n```python\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import uniform\n\nparam_dist = {'C': uniform(0.001, 10)}\nrandom_search = RandomizedSearchCV(LogisticRegression(solver='liblinear'), param_dist, n_iter=10, cv=5)\nrandom_search.fit(X_train, y_train)\n\nprint(\"Best Parameters:\", random_search.best_params_)\n```\n\n---\n\n### üîπ **3. Bayesian Optimization**\n- Uses probability to find the best hyperparameters efficiently.\n- **More advanced** than Grid/Random Search.\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0c46ab25-3949-46e1-b5e5-0941c0bdc904",
      "cell_type": "code",
      "source": "#14 What are different solvers in Logistic Regression? Which one should be used.\n#ans.### **Different Solvers in Logistic Regression & When to Use Them**  \n\nIn **Logistic Regression**, solvers are optimization algorithms used to find the best model parameters. Choosing the right solver depends on **dataset size, feature count, regularization type, and computational efficiency**.\n\n---\n\n## **1. List of Solvers in Scikit-learn Logistic Regression**\n| **Solver**  | **Best For** | **Supports L1?** | **Supports L2?** | **Supports Elastic Net?** | **Multiclass?** |\n|------------|-------------|------------------|------------------|------------------------|------------------|\n| **'liblinear'**  | Small datasets | ‚úÖ Yes | ‚úÖ Yes | ‚ùå No | ‚ùå No (One-vs-Rest only) |\n| **'lbfgs'**      | Large datasets | ‚ùå No | ‚úÖ Yes | ‚ùå No | ‚úÖ Yes (Multinomial) |\n| **'newton-cg'**  | Large datasets | ‚ùå No | ‚úÖ Yes | ‚ùå No | ‚úÖ Yes (Multinomial) |\n| **'sag'**        | Large datasets, sparse data | ‚ùå No | ‚úÖ Yes | ‚ùå No | ‚úÖ Yes (Multinomial) |\n| **'saga'**       | Very large datasets, L1/L2, Elastic Net | ‚úÖ Yes | ‚úÖ Yes | ‚úÖ Yes | ‚úÖ Yes (Multinomial) |\n\n---\n\n## **2. Explanation of Each Solver**\n### üîπ **1. 'liblinear' (Library for Large Linear Classification)**\n- **Best for**: Small datasets (<10,000 samples), binary classification.\n- **Supports**: L1 (Lasso), L2 (Ridge) regularization.\n- **Limitation**: Does **not** support multinomial classification.\n- **Use Case**: When interpretability & feature selection (L1) are needed.\n\nüîπ **Example:**\n```python\nLogisticRegression(solver='liblinear', penalty='l1')  # L1 Regularization\n```\n\n---\n\n### üîπ **2. 'lbfgs' (Limited-memory BFGS)**\n- **Best for**: Large datasets with many features.\n- **Supports**: L2 regularization only.\n- **Limitation**: No L1 or Elastic Net support.\n- **Use Case**: When using **multiclass classification** (`multi_class='multinomial'`).\n\nüîπ **Example:**\n```python\nLogisticRegression(solver='lbfgs', multi_class='multinomial')\n```\n\n---\n\n### üîπ **3. 'newton-cg' (Newton Conjugate Gradient)**\n- **Best for**: Large datasets with high-dimensional features.\n- **Supports**: L2 regularization.\n- **Limitation**: No L1 or Elastic Net support.\n- **Use Case**: Similar to **'lbfgs'**, but can be **faster in high-dimensional problems**.\n\nüîπ **Example:**\n```python\nLogisticRegression(solver='newton-cg', multi_class='multinomial')\n```\n\n---\n\n### üîπ **4. 'sag' (Stochastic Average Gradient)**\n- **Best for**: Very large datasets, sparse data.\n- **Supports**: L2 regularization.\n- **Limitation**: No L1 or Elastic Net support.\n- **Use Case**: When dealing with **sparse datasets** (e.g., NLP, text data).\n\nüîπ **Example:**\n```python\nLogisticRegression(solver='sag')\n```\n\n---\n\n### üîπ **5. 'saga' (Stochastic Average Gradient with L1/L2 Support)**\n- **Best for**: **Very large datasets (millions of samples)**, Elastic Net.\n- **Supports**: L1, L2, Elastic Net regularization.\n- **Limitation**: More computationally expensive.\n- **Use Case**: When L1 (feature selection) or Elastic Net (combination of L1 & L2) is needed.\n\nüîπ **Example:**\n```python\nLogisticRegression(solver='saga', penalty='elasticnet', l1_ratio=0.5)\n```\n\n---\n\n## **3. Which Solver Should You Use?**\n| **Scenario** | **Best Solver** |\n|-------------|----------------|\n| Small dataset (binary classification) | `'liblinear'` |\n| Large dataset (>10,000 samples) | `'lbfgs'` or `'newton-cg'` |\n| Multiclass classification | `'lbfgs'` or `'newton-cg'` |\n| Sparse datasets (text, NLP) | `'sag'` or `'saga'` |\n| L1 regularization (feature selection) | `'liblinear'` or `'saga'` |\n| Elastic Net regularization | `'saga'` |\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "63f0726e-fc18-4a68-b375-ed41ba9aeb89",
      "cell_type": "code",
      "source": "#15 how is Logistic Regression extended for multiclass classification.\n#ans.### **How Logistic Regression is Extended for Multiclass Classification**  \n\nBy default, **Logistic Regression is designed for binary classification** (i.e., two classes). However, it can be extended to **multiclass classification** (three or more classes) using two main approaches:  \n\n---\n\n## **1. One-vs-Rest (OvR) / One-vs-All (OvA)**\nüîπ **Concept:**  \n- Trains **one logistic regression model per class**.\n- Each model treats one class as **positive** and all others as **negative**.  \n- The model with the **highest probability** is chosen.  \n\nüîπ **Example (3 classes: A, B, C)**  \n- Model 1: A vs (B + C)  \n- Model 2: B vs (A + C)  \n- Model 3: C vs (A + B)  \n\nüîπ **When to Use:**  \n‚úÖ Works well for **most datasets**.  \n‚úÖ **Efficient for large datasets**.  \n‚ùå **Can be inefficient** for a **very large number of classes**.  \n\nüîπ **Scikit-learn Implementation:**  \n```python\nfrom sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression(multi_class='ovr', solver='liblinear')\nmodel.fit(X_train, y_train)\n```\n\n---\n\n## **2. Multinomial Logistic Regression (Softmax Regression)**\nüîπ **Concept:**  \n- Uses the **softmax function** to assign probabilities to each class.  \n- **Single model** learns all class probabilities simultaneously.  \n- Class with the **highest probability** is predicted.  \n\nüîπ **Softmax Formula:**  \n\\[\nP(y = k | X) = \\frac{e^{\\theta_k^T X}}{\\sum_{j=1}^{K} e^{\\theta_j^T X}}\n\\]\nwhere \\( k \\) is the class label, and \\( K \\) is the total number of classes.\n\nüîπ **When to Use:**  \n‚úÖ Better for **balanced datasets**.  \n‚úÖ **More stable than OvR** when the number of classes is small.  \n‚ùå Can be **computationally expensive** for large datasets.  \n\nüîπ **Scikit-learn Implementation:**  \n```python\nmodel = LogisticRegression(multi_class='multinomial', solver='lbfgs')\nmodel.fit(X_train, y_train)\n```\n\n---\n\n## **3. Choosing Between OvR and Multinomial Logistic Regression**\n| **Criteria** | **One-vs-Rest (OvR)** | **Multinomial (Softmax)** |\n|-------------|----------------------|--------------------------|\n| **Computational Cost** | Lower | Higher |\n| **Interpretability** | Easier | More complex |\n| **Performance** | Good for imbalanced datasets | Good for balanced datasets |\n| **Scalability** | Better for large class counts | Efficient for small class counts |\n\n---\n\n## **Conclusion**\n- **One-vs-Rest (OvR)** trains multiple binary classifiers and is efficient for large datasets.  \n- **Multinomial (Softmax)** directly optimizes for multiple classes and works well for smaller, balanced datasets.  \n- In **Scikit-learn**, `'lbfgs'` or `'newton-cg'` solvers are preferred for **multinomial logistic regression**.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "49a35694-b1e7-4c96-a649-cc14a6e82a0d",
      "cell_type": "code",
      "source": "#16.what are the advantages and disadvantages of Logistic Regression.\n#ans.Advantages:\n\n    Simple to implement and interpret.\n    Works well with linearly separable data.\n    Outputs probability scores.\n    Computationally efficient.\n\nDisadvantages:\n\n    Assumes linear decision boundary.\n    Struggles with complex relationships.\n    Sensitive to outliers.\n    Requires feature engineering for better performance.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "86d01958-cbdf-4960-8965-455d3221c492",
      "cell_type": "code",
      "source": "#17 What are some use cases of Logistic Regression.\n#ans.What are some use cases of Logistic Regression?\n\n    Medical diagnosis (e.g., predicting disease presence).\n    Credit scoring (e.g., loan approval).\n    Marketing (e.g., customer churn prediction).\n    Spam detection.\n    Fraud detection.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "81edc6f3-4d5c-476d-b535-addb8e90925c",
      "cell_type": "code",
      "source": "#18.What is the difference between Softmax Regression and Logistic Regression.\n#ans.Logistic Regression: Used for binary classification; outputs a probability for one class.\nSoftmax Regression: Used for multiclass classification; assigns probabilities to all classes, summing to 1.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e34f7a84-187d-44c1-ab13-67b97872be9b",
      "cell_type": "code",
      "source": "#19 How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification.\nOvR: Works well for datasets with imbalanced classes and is computationally efficient for large class counts.\nSoftmax: Preferred when class relationships are important and probabilistic interpretation is needed.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a4abfca7-835c-4785-b206-beb2bee2a194",
      "cell_type": "code",
      "source": "#20. How do we interpret coefficients in Logistic Regression?\n#ans.Each coefficient represents the log-odds change in the dependent variable for a one-unit change in the predictor variable.\nA positive coefficient means increasing the predictor increases the probability of the positive class.\nA negative coefficient means increasing the predictor decreases the probability of the positive class.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c8fba8e2-1740-496f-8f89-7b45432a02ba",
      "cell_type": "code",
      "source": "                                               PRACTICAL QUESTIONS",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "06497dfb-bb93-4b91-9c4d-76f246ee8a4c",
      "cell_type": "code",
      "source": "#1. Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy\n#ans.from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.datasets import load_iris\n\n# Load dataset\ndata = load_iris()\nX_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)\n\n# Train model\nmodel = LogisticRegression(max_iter=200)\nmodel.fit(X_train, y_train)\n\n# Predict and evaluate\ny_pred = model.predict(X_test)\nprint(\"Model Accuracy:\", accuracy_score(y_test, y_pred))\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0284c0f4-3e45-45f8-8957-bcb05540abdb",
      "cell_type": "code",
      "source": "2. Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1') and print the model accuracy\n\nmodel = LogisticRegression(penalty='l1', solver='liblinear')\nmodel.fit(X_train, y_train)\nprint(\"L1 Regularization Accuracy:\", accuracy_score(y_test, model.predict(X_test)))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "9d4273a9-40fe-4320-928d-1f5cc936cb22",
      "cell_type": "code",
      "source": "3. Write a Python program to train Logistic Regression with L2 regularization (Ridge) using LogisticRegression(penalty='l2'). Print model accuracy and coefficients\n\nmodel = LogisticRegression(penalty='l2', solver='lbfgs')\nmodel.fit(X_train, y_train)\nprint(\"L2 Regularization Accuracy:\", accuracy_score(y_test, model.predict(X_test)))\nprint(\"Coefficients:\", model.coef_)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "1771f205-d0e8-497a-b3ac-872beef8f735",
      "cell_type": "code",
      "source": "4. Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')\n\nmodel = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5)\nmodel.fit(X_train, y_train)\nprint(\"Elastic Net Accuracy:\", accuracy_score(y_test, model.predict(X_test)))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e3e68ebb-8e3c-4782-bfe2-3d57d36e2ba0",
      "cell_type": "code",
      "source": "5. Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'\n\nmodel = LogisticRegression(multi_class='ovr')\nmodel.fit(X_train, y_train)\nprint(\"Multiclass (OvR) Accuracy:\", accuracy_score(y_test, model.predict(X_test)))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2a3f4c48-126e-455c-84e6-c1ac53b47093",
      "cell_type": "code",
      "source": "6. Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy\n\nfrom sklearn.model_selection import GridSearchCV\n\nparams = {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2']}\ngrid = GridSearchCV(LogisticRegression(solver='saga'), param_grid=params, cv=5)\ngrid.fit(X_train, y_train)\n\nprint(\"Best Parameters:\", grid.best_params_)\nprint(\"Best Accuracy:\", grid.best_score_)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "9caeabbf-ece9-46f1-84ee-43c584966e2e",
      "cell_type": "code",
      "source": "7. Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy\n\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\n\nkf = StratifiedKFold(n_splits=5)\nscores = cross_val_score(model, X_train, y_train, cv=kf)\n\nprint(\"Average Accuracy:\", scores.mean())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "799d4320-af74-4e44-a8f9-4273f6e0e063",
      "cell_type": "code",
      "source": "#8. Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy\n\nimport pandas as pd\n\n# Load dataset\ndf = pd.read_csv(\"dataset.csv\")  # Replace with actual CSV file\nX = df.iloc[:, :-1]  # Features\ny = df.iloc[:, -1]   # Target\n\n# Split dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train model\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\n# Predict and evaluate\nprint(\"Model Accuracy:\", accuracy_score(y_test, model.predict(X_test)))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "79337f25-46a9-42fd-babb-a3e6be2f3aa0",
      "cell_type": "code",
      "source": "#9.Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in \nLogistic Regression. Print the best parameters and accuracy\n#ans.from sklearn.model_selection import RandomizedSearchCV, train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.datasets import load_iris\nfrom sklearn.metrics import accuracy_score\n\n# Load dataset\ndata = load_iris()\nX_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)\n\n# Define parameter grid\nparam_dist = {\n    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n    'penalty': ['l1', 'l2'],       # Type of regularization\n    'solver': ['liblinear', 'saga'] # Solvers that support both l1 and l2\n}\n\n# Initialize logistic regression model\nmodel = LogisticRegression(max_iter=500)\n\n# Apply RandomizedSearchCV\nrandom_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=10, cv=5, random_state=42)\nrandom_search.fit(X_train, y_train)\n\n# Get best parameters and accuracy\nbest_model = random_search.best_estimator_\ny_pred = best_model.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\n\nprint(\"Best Parameters:\", random_search.best_params_)\nprint(\"Best Model Accuracy:\", accuracy)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c72eeee9-25a0-43f7-8d8a-171a2937fb61",
      "cell_type": "code",
      "source": "#10. Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy\n#ans.from sklearn.multiclass import OneVsOneClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n# Load dataset\ndata = load_iris()\nX_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)\n\n# Initialize Logistic Regression with One-vs-One (OvO)\novo_model = OneVsOneClassifier(LogisticRegression(max_iter=500))\novo_model.fit(X_train, y_train)\n\n# Make predictions\ny_pred = ovo_model.predict(X_test)\n\n# Evaluate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"One-vs-One (OvO) Accuracy:\", accuracy)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ebbb3c1b-8b72-4b26-b8ec-dbd4b490d580",
      "cell_type": "code",
      "source": "11. Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary \nclassification\n#ans.import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.datasets import make_classification\n\n# Generate a binary classification dataset\nX, y = make_classification(n_samples=1000, n_features=10, random_state=42, n_classes=2)\n\n# Split into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train Logistic Regression model\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\n# Predict on test data\ny_pred = model.predict(X_test)\n\n# Compute confusion matrix\ncm = confusion_matrix(y_test, y_pred)\n\n# Visualize confusion matrix\nplt.figure(figsize=(6, 4))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4d889044-ba02-4377-9076-cd6d5a12adce",
      "cell_type": "code",
      "source": "#12.Write a Python program to train a Logistic Regression model and evaluate its performance using Precision, \nRecall, and F1-Score\n#ans.from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import precision_score, recall_score, f1_score, classification_report\nfrom sklearn.datasets import make_classification\n\n# Generate a binary classification dataset\nX, y = make_classification(n_samples=1000, n_features=10, random_state=42, n_classes=2)\n\n# Split into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train Logistic Regression model\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\n# Predict on test data\ny_pred = model.predict(X_test)\n\n# Evaluate performance\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\n# Print results\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1-Score: {f1:.4f}\")\nprint(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ce0ee5ed-403c-4d6c-a3ab-162e5f29e7fc",
      "cell_type": "code",
      "source": "#13.Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to \nimprove model performance\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.datasets import make_classification\nimport numpy as np\n\n# Generate an imbalanced dataset\nX, y = make_classification(n_samples=1000, n_features=10, weights=[0.9, 0.1], random_state=42, n_classes=2)\n\n# Split into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Train Logistic Regression model without class weights (Baseline)\nmodel_baseline = LogisticRegression()\nmodel_baseline.fit(X_train, y_train)\ny_pred_baseline = model_baseline.predict(X_test)\n\n# Train Logistic Regression model with class weights\nmodel_weighted = LogisticRegression(class_weight='balanced')\nmodel_weighted.fit(X_train, y_train)\ny_pred_weighted = model_weighted.predict(X_test)\n\n# Evaluate models\nprint(\"Baseline Model Performance:\")\nprint(classification_report(y_test, y_pred_baseline))\n\nprint(\"\\nWeighted Model Performance:\")\nprint(classifica\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6be3498f-1294-4bc6-b9fa-07bd08c39359",
      "cell_type": "code",
      "source": "#14. Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and \nevaluate performance\n#ans \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.datasets import make_classification\nimport numpy as np\n\n# Generate an imbalanced dataset\nX, y = make_classification(n_samples=1000, n_features=10, weights=[0.9, 0.1], random_state=42, n_classes=2)\n\n# Split into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Train Logistic Regression model without class weights (Baseline)\nmodel_baseline = LogisticRegression()\nmodel_baseline.fit(X_train, y_train)\ny_pred_baseline = model_baseline.predict(X_test)\n\n# Train Logistic Regression model with class weights\nmodel_weighted = LogisticRegression(class_weight='balanced')\nmodel_weighted.fit(X_train, y_train)\ny_pred_weighted = model_weighted.predict(X_test)\n\n# Evaluate models\nprint(\"Baseline Model Performance:\")\nprint(classification_report(y_test, y_pred_baseline))\n\nprint(\"\\nWeighted Model Performance:\")\nprint(classification_report(y_test, y_pred_weighted))\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2bd1252a-c4f5-4c6d-8720-1fccf10480f3",
      "cell_type": "code",
      "source": "#15. Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression \nmodel. Evaluate its accuracy and compare results with and without scaling\n#ans.\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.datasets import make_classification\n\n# Generate a dataset\nX, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n\n# Split into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train Logistic Regression without scaling\nmodel_no_scaling = LogisticRegression()\nmodel_no_scaling.fit(X_train, y_train)\ny_pred_no_scaling = model_no_scaling.predict(X_test)\naccuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n\n# Apply Standardization (Feature Scaling)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Train Logistic Regression with scaling\nmodel_with_scaling = LogisticRegression()\nmodel_with_scaling.fit(X_train_scaled, y_train)\ny_pred_with_scaling = model_with_scaling.predict(X_test_scaled)\naccuracy_with_scaling = accuracy_score(y_test, y_pred_with_scaling)\n\n# Print results\nprint(f\"Accuracy without Scaling: {accuracy_no_scaling:.4f}\")\nprint(f\"Accuracy with Scaling: {accuracy_with_scaling:.4f}\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d82d43b3-520d-4109-8691-ffc5de7ae7a9",
      "cell_type": "code",
      "source": "#16 Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score, roc_curve, auc\nfrom sklearn.datasets import make_classification\nimport matplotlib.pyplot as plt\n\n# Generate a binary classification dataset\nX, y = make_classification(n_samples=1000, n_features=10, random_state=42, n_classes=2)\n\n# Split into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train Logistic Regression model\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\n# Predict probabilities for the positive class\ny_proba = model.predict_proba(X_test)[:, 1]\n\n# Compute ROC-AUC score\nroc_auc = roc_auc_score(y_test, y_proba)\nprint(f\"ROC-AUC Score: {roc_auc:.4f}\")\n\n# Compute ROC curve\nfpr, tpr, _ = roc_curve(y_test, y_proba)\n\n# Plot ROC curve\nplt.figure(figsize=(6, 4))\nplt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.4f})\", color=\"blue\")\nplt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")  # Diagonal line\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve\")\nplt.legend(loc=\"lower right\")\nplt.show()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5bdd274a-7371-4eed-8b61-d14358865a08",
      "cell_type": "code",
      "source": "#17 Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.datasets import make_classification\n\n# Generate a dataset\nX, y = make_classification(n_samples=1000, n_features=10, random_state=42, n_classes=2)\n\n# Split into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train Logistic Regression with a custom learning rate (C=0.5)\nmodel = LogisticRegression(C=0.5, max_iter=500)\nmodel.fit(X_train, y_train)\n\n# Predict and evaluate\ny_pred = model.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\n\nprint(f\"Model Accuracy with C=0.5: {accuracy:.4f}\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6229a942-e46f-4335-9339-273240b48eea",
      "cell_type": "code",
      "source": "#18. Write a Python program to train Logistic Regression and identify important features based on model coefficients\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.datasets import make_classification\n\n# Generate a dataset with feature names\nX, y = make_classification(n_samples=1000, n_features=10, random_state=42, n_classes=2)\nfeature_names = [f'Feature {i}' for i in range(1, 11)]\n\n# Split into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train Logistic Regression model\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\n# Get feature importance (coefficients)\ncoefficients = model.coef_[0]\n\n# Create a DataFrame to display feature importance\nfeature_importance = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefficients})\nfeature_importance['Absolute Coefficient'] = np.abs(feature_importance['Coefficient'])\nfeature_importance = feature_importance.sort_values(by='Absolute Coefficient', ascending=False)\n\n# Print feature importance\nprint(\"Feature Importance based on Logistic Regression Coefficients:\")\nprint(feature_importance[['Feature', 'Coefficient']])\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "89faa6ee-8f6e-4dca-8903-83ac84216c1d",
      "cell_type": "code",
      "source": "#19.Write a Python program to train Logistic Regression and evaluate its performance using Cohen‚Äôs Kappa \nScore\n#ans.from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score\nfrom sklearn.datasets import make_classification\n\n# Generate a binary classification dataset\nX, y = make_classification(n_samples=1000, n_features=10, random_state=42, n_classes=2)\n\n# Split into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train Logistic Regression model\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\n# Predict on test data\ny_pred = model.predict(X_test)\n\n# Evaluate performance using Cohen's Kappa Score\nkappa_score = cohen_kappa_score(y_test, y_pred)\naccuracy = accuracy_score(y_test, y_pred)\n\n# Print results\nprint(f\"Model Accuracy: {accuracy:.4f}\")\nprint(f\"Cohen's Kappa Score: {kappa_score:.4f}\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c82c7825-345b-4fbe-869d-3be49bdd97f4",
      "cell_type": "code",
      "source": "#20 Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary \nclassification\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import precision_recall_curve, auc\nfrom sklearn.datasets import make_classification\n\n# Generate a binary classification dataset\nX, y = make_classification(n_samples=1000, n_features=10, random_state=42, n_classes=2)\n\n# Split into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train Logistic Regression model\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\n# Predict probabilities\ny_proba = model.predict_proba(X_test)[:, 1]\n\n# Compute Precision-Recall values\nprecision, recall, _ = precision_recall_curve(y_test, y_proba)\npr_auc = auc(recall, precision)\n\n# Plot Precision-Recall curve\nplt.figure(figsize=(6, 4))\nplt.plot(recall, precision, label=f\"PR Curve (AUC = {pr_auc:.4f})\", color=\"blue\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Precision-Recall Curve\")\nplt.legend(loc=\"lower left\")\nplt.grid()\nplt.show()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3c679125-0931-4e91-9d73-61712cdf5f6b",
      "cell_type": "code",
      "source": "#21.Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare \ntheir accuracy\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.datasets import make_classification\n\n# Generate a binary classification dataset\nX, y = make_classification(n_samples=1000, n_features=10, random_state=42, n_classes=2)\n\n# Split into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Define solvers to compare\nsolvers = ['liblinear', 'saga', 'lbfgs']\naccuracies = {}\n\n# Train and evaluate Logistic Regression with different solvers\nfor solver in solvers:\n    model = LogisticRegress\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "9608e8f4-a6b2-419c-a2b7-85dc83af9340",
      "cell_type": "code",
      "source": "#22. Write a Python program to train Logistic Regression and evaluate its performance using Matthews \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import matthews_corrcoef, accuracy_score\nfrom sklearn.datasets import make_classification\n\n# Generate a binary classification dataset\nX, y = make_classification(n_samples=1000, n_features=10, random_state=42, n_classes=2)\n\n# Split into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train Logistic Regression model\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\n# Predict on test data\ny_pred = model.predict(X_test)\n\n# Compute MCC\nmcc_score = matthews_corrcoef(y_test, y_pred)\naccuracy = accuracy_score(y_test, y_pred)\n\n# Print results\nprint(f\"Model Accuracy: {accuracy:.4f}\")\nprint(f\"Matthews Correlation Coefficient (MCC): {mcc_score:.4f}\")\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3fd9b24f-9d4b-4535-9f96-3009edcf396a",
      "cell_type": "code",
      "source": "#23.Write a Python program to train Logistic Regression on both raw and standardized data. Compare their \naccuracy to see the impact of feature scaling\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.datasets import make_classification\n\n# Generate a dataset\nX, y = make_classification(n_samples=1000, n_features=10, random_state=42, n_classes=2)\n\n# Split into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train Logistic Regression on raw data\nmodel_raw = LogisticRegression()\nmodel_raw.fit(X_train, y_train)\ny_pred_raw = model_raw.predict(X_test)\naccuracy_raw = accuracy_score(y_test, y_pred_raw)\n\n# Apply Standardization (Feature Scaling)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Train Logistic Regression on standardized data\nmodel_scaled = LogisticRegression()\nmodel_scaled.fit(X_train_scaled, y_train)\ny_pred_scaled = model_scaled.predict(X_test_scaled)\naccuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n\n# Print comparison results\nprint(f\"Accuracy on Raw Data: {accuracy_raw:.4f}\")\nprint(f\"Accuracy on Standardized Data: {accuracy_scaled:.4f}\")\n\n# Compare results\nif accuracy_scaled > accuracy_raw:\n    print(\"Feature scaling improved the model performance.\")\nelif accuracy_scaled < accuracy_raw:\n    print(\"Feature scaling reduced the model performance.\")\nelse:\n    print(\"Feature scaling had no impact on the model performance.\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ca5a0f37-fa98-43fe-834b-8b909452be0d",
      "cell_type": "code",
      "source": "#24.Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using \ncross-validation\n#ans.from sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.datasets import make_classification\nfrom sklearn.metrics import accuracy_score\n\n# Generate a dataset\nX, y = make_classification(n_samples=1000, n_features=10, random_state=42, n_classes=2)\n\n# Split into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Define hyperparameter grid for C\nparam_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n\n# Perform Grid Search with cross-validation\ngrid_search = GridSearchCV(LogisticRegression(max_iter=500), param_grid, cv=5, scoring='accuracy')\ngrid_search.fit(X_train, y_train)\n\n# Get the best C value\nbest_C = grid_search.best_params_['C']\nprint(f\"Optimal C value: {best_C}\")\n\n# Train Logistic Regression with the best C\nbest_model = LogisticRegression(C=best_C, max_iter=500)\nbest_model.fit(X_train, y_train)\n\n# Predict and evaluate accuracy\ny_pred = best_model.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Model Accuracy with Optimal C: {accuracy:.4f}\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "71635eec-951f-4f28-8693-8b8a050f1e6a",
      "cell_type": "code",
      "source": "#25.Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to \nmake predictions\n#ans.\nimport joblib\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.datasets import make_classification\nfrom sklearn.metrics import accuracy_score\n\n# Generate a dataset\nX, y = make_classification(n_samples=1000, n_features=10, random_state=42, n_classes=2)\n\n# Split into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train Logistic Regression model\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\n# Save the trained model\njoblib.dump(model, \"logistic_model.pkl\")\nprint(\"Model saved successfully!\")\n\n# Load the saved model\nloaded_model = joblib.load(\"logistic_model.pkl\")\nprint(\"Model loaded successfully!\")\n\n# Make predictions with the loaded model\ny_pred = loaded_model.predict(X_test)\n\n# Evaluate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Model Accuracy: {accuracy:.4f}\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "35ba3d5f-fe34-4373-8487-1be11ca469ca",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d3657b44-f0e5-4b92-a3f5-42c7e7e62ca8",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f33e6833-7be4-4ee4-97ef-9330598cf0ed",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "b7f0a90a-0fd4-4763-8884-b6a4b4c60ad8",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "258c8bff-31b5-46c0-bd23-a87c912aba07",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "15ed6aad-e3ac-4941-9a12-f0fe530d184f",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "1cc22bf4-877c-4e86-843c-274d775af926",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "cfccee5a-6837-45b4-aa38-4c5c7ab27cb7",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}